{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8513841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Enhanced Hungarian Matching Analysis\n",
      "============================================================\n",
      "Dataset: 200 units (50.0 treated, 150.0 controls)\n",
      "Covariates: 5\n",
      "True ATT: 2.0944\n",
      "Running 1-to-1 Hungarian...\n",
      "Running 1-to-3 Flow...\n",
      "Running 1-to-3 Sequential...\n",
      "Running 1-to-3 Duplication...\n",
      "Running 1-to-3 Greedy kNN...\n",
      "================================================================================\n",
      "COMPREHENSIVE HUNGARIAN MATCHING COMPARISON\n",
      "================================================================================\n",
      "\n",
      "📊 ATT ESTIMATION RESULTS\n",
      "--------------------------------------------------\n",
      "True ATT: 2.0944\n",
      "\n",
      "1-to-1 Hungarian    :  2.4538 (bias: +0.3594,  17.2%)\n",
      "1-to-3 Flow         :  2.2553 (bias: +0.1609,   7.7%)\n",
      "1-to-3 Sequential   :  2.2553 (bias: +0.1609,   7.7%)\n",
      "1-to-3 Duplication  :  2.2553 (bias: +0.1609,   7.7%)\n",
      "1-to-3 Greedy kNN   :  2.2553 (bias: +0.1609,   7.7%)\n",
      "\n",
      "🎯 BALANCE & QUALITY METRICS\n",
      "--------------------------------------------------\n",
      "Method               Balance  Matches  Distance Time(s) \n",
      "--------------------------------------------------\n",
      "1-to-1 Hungarian     0.3828   1.00     1.0344   0.000   \n",
      "1-to-3 Flow          0.3580   3.00     1.3881   0.273   \n",
      "1-to-3 Sequential    0.3728   3.00     1.4123   0.001   \n",
      "1-to-3 Duplication   0.3580   3.00     1.3881   0.001   \n",
      "1-to-3 Greedy kNN    0.4067   3.00     1.5843   0.002   \n",
      "\n",
      "📈 DETAILED STATISTICS\n",
      "--------------------------------------------------\n",
      "🏆 Best ATT Estimation: 1-to-3 Flow\n",
      "⚖️  Best Balance:        1-to-3 Flow\n",
      "⚡ Fastest:             1-to-1 Hungarian\n",
      "\n",
      "📊 BALANCE BY COVARIATE\n",
      "--------------------------------------------------\n",
      "1-to-1 Hungarian    : [0.358 0.376 0.379 0.383 0.419]\n",
      "1-to-3 Flow         : [0.305 0.261 0.341 0.360 0.522]\n",
      "1-to-3 Sequential   : [0.314 0.307 0.355 0.394 0.494]\n",
      "1-to-3 Duplication  : [0.305 0.261 0.341 0.360 0.522]\n",
      "1-to-3 Greedy kNN   : [0.405 0.378 0.335 0.391 0.525]\n",
      "\n",
      "============================================================\n",
      "🎲 Monte Carlo Simulation (optional - set to True to run)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import networkx as nx\n",
    "import time\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# -----------------------------\n",
    "# Hungarian 1-to-1 Matching (Your Original)\n",
    "# -----------------------------\n",
    "def att_hungarian_1to1(X, T, Y):\n",
    "    \"\"\"Original 1-to-1 Hungarian matching.\"\"\"\n",
    "    treated_idx = np.where(T == 1)[0]\n",
    "    control_idx = np.where(T == 0)[0]\n",
    "    cost = np.linalg.norm(X[treated_idx][:, None] - X[control_idx][None, :], axis=2)\n",
    "    row, col = linear_sum_assignment(cost)\n",
    "    Y_treated = Y[treated_idx[row]]\n",
    "    Y_control = Y[control_idx[col]]\n",
    "    att = np.mean(Y_treated - Y_control)\n",
    "    match = {i: [j] for i, j in zip(row, col)}\n",
    "    return att, match, treated_idx, control_idx\n",
    "\n",
    "# -----------------------------\n",
    "# Hungarian 1-to-k Matching (Your Original - Min Cost Flow)\n",
    "# -----------------------------\n",
    "def att_hungarian_1tok_flow(X, T, Y, k=3):\n",
    "    \"\"\"Original 1-to-k matching using min-cost max-flow.\"\"\"\n",
    "    treated_idx = np.where(T == 1)[0]\n",
    "    control_idx = np.where(T == 0)[0]\n",
    "    \n",
    "    G = nx.DiGraph()\n",
    "    source, sink = \"s\", \"t\"\n",
    "    \n",
    "    # Add source to treated edges\n",
    "    for i in range(len(treated_idx)):\n",
    "        G.add_edge(source, f\"T{i}\", capacity=k, weight=0)\n",
    "    \n",
    "    # Add control to sink edges\n",
    "    for j in range(len(control_idx)):\n",
    "        G.add_edge(f\"C{j}\", sink, capacity=1, weight=0)\n",
    "    \n",
    "    # Add treated to control edges with costs\n",
    "    for i in range(len(treated_idx)):\n",
    "        for j in range(len(control_idx)):\n",
    "            dist = np.linalg.norm(X[treated_idx[i]] - X[control_idx[j]])\n",
    "            G.add_edge(f\"T{i}\", f\"C{j}\", capacity=1, weight=int(dist * 1e6))\n",
    "    \n",
    "    flow = nx.max_flow_min_cost(G, source, sink)\n",
    "    \n",
    "    matches = {i: [] for i in range(len(treated_idx))}\n",
    "    for i in range(len(treated_idx)):\n",
    "        for j in range(len(control_idx)):\n",
    "            if flow[f\"T{i}\"].get(f\"C{j}\", 0) > 0:\n",
    "                matches[i].append(j)\n",
    "    \n",
    "    att_list = []\n",
    "    for i, matched_js in matches.items():\n",
    "        if matched_js:\n",
    "            treated_y = Y[treated_idx[i]]\n",
    "            matched_y = Y[control_idx][matched_js].mean()\n",
    "            att_list.append(treated_y - matched_y)\n",
    "    \n",
    "    att = np.mean(att_list)\n",
    "    return att, matches, treated_idx, control_idx\n",
    "\n",
    "# -----------------------------\n",
    "# NEW: Sequential Hungarian\n",
    "# -----------------------------\n",
    "def att_hungarian_sequential(X, T, Y, k=3):\n",
    "    \"\"\"Sequential Hungarian: Run Hungarian k times, removing matched controls.\"\"\"\n",
    "    treated_idx = np.where(T == 1)[0]\n",
    "    control_idx = np.where(T == 0)[0]\n",
    "    \n",
    "    if k > len(control_idx):\n",
    "        raise ValueError(f\"k={k} cannot exceed number of controls ({len(control_idx)})\")\n",
    "    \n",
    "    # Initialize\n",
    "    matches = {i: [] for i in range(len(treated_idx))}\n",
    "    available_controls = set(range(len(control_idx)))\n",
    "    \n",
    "    for round_num in range(k):\n",
    "        if not available_controls:\n",
    "            break\n",
    "        \n",
    "        # Create cost matrix with only available controls\n",
    "        available_list = sorted(available_controls)\n",
    "        cost_matrix = np.linalg.norm(\n",
    "            X[treated_idx][:, None] - X[control_idx[available_list]][None, :], \n",
    "            axis=2\n",
    "        )\n",
    "        \n",
    "        # Solve Hungarian\n",
    "        row_indices, col_indices = linear_sum_assignment(cost_matrix)\n",
    "        \n",
    "        # Store matches and remove used controls\n",
    "        for treated_idx_pos, available_pos in zip(row_indices, col_indices):\n",
    "            control_idx_pos = available_list[available_pos]\n",
    "            matches[treated_idx_pos].append(control_idx_pos)\n",
    "            available_controls.remove(control_idx_pos)\n",
    "    \n",
    "    # Calculate ATT\n",
    "    att_list = []\n",
    "    for i, matched_js in matches.items():\n",
    "        if matched_js:\n",
    "            treated_y = Y[treated_idx[i]]\n",
    "            matched_y = Y[control_idx][matched_js].mean()\n",
    "            att_list.append(treated_y - matched_y)\n",
    "    \n",
    "    att = np.mean(att_list)\n",
    "    return att, matches, treated_idx, control_idx\n",
    "\n",
    "# -----------------------------\n",
    "# NEW: Graph Duplication Hungarian\n",
    "# -----------------------------\n",
    "def att_hungarian_duplication(X, T, Y, k=3):\n",
    "    \"\"\"Graph Duplication: Create k copies of treated units, run standard Hungarian.\"\"\"\n",
    "    treated_idx = np.where(T == 1)[0]\n",
    "    control_idx = np.where(T == 0)[0]\n",
    "    \n",
    "    if k > len(control_idx):\n",
    "        raise ValueError(f\"k={k} cannot exceed number of controls ({len(control_idx)})\")\n",
    "    \n",
    "    # Create expanded cost matrix: (k*n_treated, n_controls)\n",
    "    n_treated = len(treated_idx)\n",
    "    n_controls = len(control_idx)\n",
    "    \n",
    "    # Tile the cost matrix k times\n",
    "    base_cost = np.linalg.norm(X[treated_idx][:, None] - X[control_idx][None, :], axis=2)\n",
    "    expanded_cost = np.tile(base_cost, (k, 1))\n",
    "    \n",
    "    # Solve Hungarian on expanded problem\n",
    "    row_indices, col_indices = linear_sum_assignment(expanded_cost)\n",
    "    \n",
    "    # Group results by original treated unit\n",
    "    matches = {i: [] for i in range(n_treated)}\n",
    "    for expanded_row, control in zip(row_indices, col_indices):\n",
    "        original_treated = expanded_row % n_treated\n",
    "        matches[original_treated].append(control)\n",
    "    \n",
    "    # Calculate ATT\n",
    "    att_list = []\n",
    "    for i, matched_js in matches.items():\n",
    "        if matched_js:\n",
    "            treated_y = Y[treated_idx[i]]\n",
    "            matched_y = Y[control_idx][matched_js].mean()\n",
    "            att_list.append(treated_y - matched_y)\n",
    "    \n",
    "    att = np.mean(att_list)\n",
    "    return att, matches, treated_idx, control_idx\n",
    "\n",
    "# -----------------------------\n",
    "# NEW: Greedy k-Nearest Neighbors (Baseline)\n",
    "# -----------------------------\n",
    "def att_greedy_knn(X, T, Y, k=3):\n",
    "    \"\"\"Greedy k-NN matching for comparison.\"\"\"\n",
    "    treated_idx = np.where(T == 1)[0]\n",
    "    control_idx = np.where(T == 0)[0]\n",
    "    \n",
    "    matches = {i: [] for i in range(len(treated_idx))}\n",
    "    used_controls = set()\n",
    "    \n",
    "    for i in range(len(treated_idx)):\n",
    "        # Calculate distances to all unused controls\n",
    "        available_controls = [j for j in range(len(control_idx)) if j not in used_controls]\n",
    "        if len(available_controls) < k:\n",
    "            available_controls = list(range(len(control_idx)))  # Allow reuse if necessary\n",
    "        \n",
    "        distances = np.linalg.norm(\n",
    "            X[treated_idx[i]] - X[control_idx[available_controls]], axis=1\n",
    "        )\n",
    "        \n",
    "        # Take k nearest\n",
    "        nearest_k = np.argsort(distances)[:k]\n",
    "        matches[i] = [available_controls[j] for j in nearest_k]\n",
    "        \n",
    "        # Mark as used (for without replacement)\n",
    "        for j in nearest_k:\n",
    "            used_controls.add(available_controls[j])\n",
    "    \n",
    "    # Calculate ATT\n",
    "    att_list = []\n",
    "    for i, matched_js in matches.items():\n",
    "        if matched_js:\n",
    "            treated_y = Y[treated_idx[i]]\n",
    "            matched_y = Y[control_idx][matched_js].mean()\n",
    "            att_list.append(treated_y - matched_y)\n",
    "    \n",
    "    att = np.mean(att_list)\n",
    "    return att, matches, treated_idx, control_idx\n",
    "\n",
    "# -----------------------------\n",
    "# Enhanced Data Generator\n",
    "# -----------------------------\n",
    "def generate_data(n_treated=100, n_control=300, p=5, tau=2.0, hetero=False, \n",
    "                  noise_level=1.0, confounding_strength=0.5, seed=42):\n",
    "    \"\"\"Enhanced data generator with more realistic confounding.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Generate covariates\n",
    "    X = np.random.normal(0, 1, size=(n_treated + n_control, p))\n",
    "    \n",
    "    # Treatment assignment (first n_treated units are treated)\n",
    "    T = np.zeros(n_treated + n_control)\n",
    "    T[:n_treated] = 1\n",
    "    \n",
    "    # Potential outcomes with confounding\n",
    "    # Y0 depends on X with some confounding\n",
    "    beta = np.random.normal(confounding_strength, 0.1, p)\n",
    "    Y0 = X @ beta + np.random.normal(0, noise_level, X.shape[0])\n",
    "    \n",
    "    # Treatment effect (constant or heterogeneous)\n",
    "    if hetero:\n",
    "        tau_x = tau * (1 + 0.5 * X[:, 0])  # Effect varies with first covariate\n",
    "    else:\n",
    "        tau_x = np.full(X.shape[0], tau)\n",
    "    \n",
    "    Y1 = Y0 + tau_x\n",
    "    Y = T * Y1 + (1 - T) * Y0\n",
    "    \n",
    "    return X, T, Y, tau_x\n",
    "\n",
    "# -----------------------------\n",
    "# Enhanced Evaluation Metrics\n",
    "# -----------------------------\n",
    "def comprehensive_evaluation(X, T, Y, matches, treated_idx, control_idx, tau_x, method_name):\n",
    "    \"\"\"Comprehensive evaluation of matching quality.\"\"\"\n",
    "    results = {'method': method_name}\n",
    "    \n",
    "    # 1. ATT Estimation\n",
    "    att_list = []\n",
    "    for i, matched_js in matches.items():\n",
    "        if matched_js:\n",
    "            treated_y = Y[treated_idx[i]]\n",
    "            matched_y = Y[control_idx][matched_js].mean()\n",
    "            att_list.append(treated_y - matched_y)\n",
    "    \n",
    "    results['att_estimate'] = np.mean(att_list)\n",
    "    results['att_true'] = np.mean(tau_x[T == 1])\n",
    "    results['att_bias'] = results['att_estimate'] - results['att_true']\n",
    "    results['att_mse'] = results['att_bias'] ** 2\n",
    "    \n",
    "    # 2. Covariate Balance\n",
    "    balance_diffs = []\n",
    "    for i, matched_js in matches.items():\n",
    "        if matched_js:\n",
    "            treated_x = X[treated_idx[i]]\n",
    "            matched_x = X[control_idx][matched_js].mean(axis=0)\n",
    "            balance_diffs.append(treated_x - matched_x)\n",
    "    \n",
    "    if balance_diffs:\n",
    "        balance_matrix = np.array(balance_diffs)\n",
    "        results['mean_balance'] = np.abs(balance_matrix).mean()\n",
    "        results['max_balance'] = np.abs(balance_matrix).max()\n",
    "        results['balance_by_covariate'] = np.abs(balance_matrix).mean(axis=0)\n",
    "    else:\n",
    "        results['mean_balance'] = np.inf\n",
    "        results['max_balance'] = np.inf\n",
    "        results['balance_by_covariate'] = np.full(X.shape[1], np.inf)\n",
    "    \n",
    "    # 3. Matching Statistics\n",
    "    match_sizes = [len(matched_js) for matched_js in matches.values()]\n",
    "    results['avg_matches_per_treated'] = np.mean(match_sizes)\n",
    "    results['min_matches_per_treated'] = np.min(match_sizes)\n",
    "    results['unmatched_treated'] = sum(1 for size in match_sizes if size == 0)\n",
    "    \n",
    "    # 4. Distance Statistics\n",
    "    distances = []\n",
    "    for i, matched_js in matches.items():\n",
    "        if matched_js:\n",
    "            treated_x = X[treated_idx[i]]\n",
    "            for j in matched_js:\n",
    "                control_x = X[control_idx[j]]\n",
    "                distances.append(np.linalg.norm(treated_x - control_x))\n",
    "    \n",
    "    if distances:\n",
    "        results['mean_distance'] = np.mean(distances)\n",
    "        results['median_distance'] = np.median(distances)\n",
    "        results['max_distance'] = np.max(distances)\n",
    "    else:\n",
    "        results['mean_distance'] = np.inf\n",
    "        results['median_distance'] = np.inf\n",
    "        results['max_distance'] = np.inf\n",
    "    \n",
    "    return results\n",
    "\n",
    "# -----------------------------\n",
    "# Method Comparison Framework\n",
    "# -----------------------------\n",
    "def compare_all_methods(X, T, Y, tau_x, k=3, verbose=True):\n",
    "    \"\"\"Compare all matching methods side by side.\"\"\"\n",
    "    methods = {\n",
    "        '1-to-1 Hungarian': lambda: att_hungarian_1to1(X, T, Y),\n",
    "        f'1-to-{k} Flow': lambda: att_hungarian_1tok_flow(X, T, Y, k),\n",
    "        f'1-to-{k} Sequential': lambda: att_hungarian_sequential(X, T, Y, k),\n",
    "        f'1-to-{k} Duplication': lambda: att_hungarian_duplication(X, T, Y, k),\n",
    "        f'1-to-{k} Greedy kNN': lambda: att_greedy_knn(X, T, Y, k),\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for method_name, method_func in methods.items():\n",
    "        if verbose:\n",
    "            print(f\"Running {method_name}...\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            att, matches, treated_idx, control_idx = method_func()\n",
    "            runtime = time.time() - start_time\n",
    "            \n",
    "            eval_results = comprehensive_evaluation(\n",
    "                X, T, Y, matches, treated_idx, control_idx, tau_x, method_name\n",
    "            )\n",
    "            eval_results['runtime'] = runtime\n",
    "            eval_results['success'] = True\n",
    "            \n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"  Error: {str(e)}\")\n",
    "            eval_results = {\n",
    "                'method': method_name,\n",
    "                'runtime': time.time() - start_time,\n",
    "                'success': False,\n",
    "                'error': str(e)\n",
    "            }\n",
    "        \n",
    "        results.append(eval_results)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# -----------------------------\n",
    "# Enhanced Results Display\n",
    "# -----------------------------\n",
    "def display_results(df_results, detailed=True):\n",
    "    \"\"\"Display comprehensive results comparison.\"\"\"\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"COMPREHENSIVE HUNGARIAN MATCHING COMPARISON\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Filter successful methods\n",
    "    successful = df_results[df_results['success'] == True].copy()\n",
    "    \n",
    "    if len(successful) == 0:\n",
    "        print(\"No methods completed successfully!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n📊 ATT ESTIMATION RESULTS\")\n",
    "    print(\"-\" * 50)\n",
    "    true_att = successful['att_true'].iloc[0]\n",
    "    print(f\"True ATT: {true_att:.4f}\")\n",
    "    print()\n",
    "    \n",
    "    for _, row in successful.iterrows():\n",
    "        bias = row['att_bias']\n",
    "        bias_pct = 100 * abs(bias) / abs(true_att) if true_att != 0 else 0\n",
    "        print(f\"{row['method']:<20}: {row['att_estimate']:>7.4f} \"\n",
    "              f\"(bias: {bias:>+7.4f}, {bias_pct:>5.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n🎯 BALANCE & QUALITY METRICS\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{'Method':<20} {'Balance':<8} {'Matches':<8} {'Distance':<8} {'Time(s)':<8}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for _, row in successful.iterrows():\n",
    "        print(f\"{row['method']:<20} \"\n",
    "              f\"{row['mean_balance']:<8.4f} \"\n",
    "              f\"{row['avg_matches_per_treated']:<8.2f} \"\n",
    "              f\"{row['mean_distance']:<8.4f} \"\n",
    "              f\"{row['runtime']:<8.3f}\")\n",
    "    \n",
    "    if detailed:\n",
    "        print(f\"\\n📈 DETAILED STATISTICS\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Best method by different criteria\n",
    "        best_att = successful.loc[successful['att_mse'].idxmin(), 'method']\n",
    "        best_balance = successful.loc[successful['mean_balance'].idxmin(), 'method']\n",
    "        fastest = successful.loc[successful['runtime'].idxmin(), 'method']\n",
    "        \n",
    "        print(f\"🏆 Best ATT Estimation: {best_att}\")\n",
    "        print(f\"⚖️  Best Balance:        {best_balance}\")\n",
    "        print(f\"⚡ Fastest:             {fastest}\")\n",
    "        \n",
    "        print(f\"\\n📊 BALANCE BY COVARIATE\")\n",
    "        print(\"-\" * 50)\n",
    "        for i, row in successful.iterrows():\n",
    "            if 'balance_by_covariate' in row and hasattr(row['balance_by_covariate'], '__len__'):\n",
    "                balance_str = \" \".join([f\"{x:.3f}\" for x in row['balance_by_covariate']])\n",
    "                print(f\"{row['method']:<20}: [{balance_str}]\")\n",
    "\n",
    "# -----------------------------\n",
    "# Monte Carlo Simulation\n",
    "# -----------------------------\n",
    "def monte_carlo_comparison(n_simulations=50, **data_params):\n",
    "    \"\"\"Run Monte Carlo comparison across multiple datasets.\"\"\"\n",
    "    print(f\"Running Monte Carlo simulation with {n_simulations} replications...\")\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for sim in range(n_simulations):\n",
    "        if sim % 10 == 0:\n",
    "            print(f\"  Simulation {sim+1}/{n_simulations}\")\n",
    "        \n",
    "        # Generate new data\n",
    "        data_params['seed'] = sim + 42\n",
    "        X, T, Y, tau_x = generate_data(**data_params)\n",
    "        \n",
    "        # Compare methods (non-verbose)\n",
    "        sim_results = compare_all_methods(X, T, Y, tau_x, verbose=False)\n",
    "        sim_results['simulation'] = sim\n",
    "        all_results.append(sim_results)\n",
    "    \n",
    "    # Combine results\n",
    "    combined_df = pd.concat(all_results, ignore_index=True)\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(f\"\\n📊 MONTE CARLO SUMMARY ({n_simulations} simulations)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    successful_df = combined_df[combined_df['success'] == True]\n",
    "    summary = successful_df.groupby('method').agg({\n",
    "        'att_bias': ['mean', 'std'],\n",
    "        'att_mse': 'mean',\n",
    "        'mean_balance': ['mean', 'std'],\n",
    "        'runtime': ['mean', 'std']\n",
    "    }).round(4)\n",
    "    \n",
    "    print(summary)\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "# -----------------------------\n",
    "# Main Script\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🚀 Enhanced Hungarian Matching Analysis\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Generate data\n",
    "    X, T, Y, tau_x = generate_data(n_treated=50, n_control=150, p=5, tau=2.0, hetero=True)\n",
    "    \n",
    "    print(f\"Dataset: {len(X)} units ({sum(T)} treated, {sum(1-T)} controls)\")\n",
    "    print(f\"Covariates: {X.shape[1]}\")\n",
    "    print(f\"True ATT: {np.mean(tau_x[T==1]):.4f}\")\n",
    "    \n",
    "    # Single comparison\n",
    "    results_df = compare_all_methods(X, T, Y, tau_x, k=3)\n",
    "    display_results(results_df, detailed=True)\n",
    "    \n",
    "    # Optional: Monte Carlo simulation\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(\"🎲 Monte Carlo Simulation (optional - set to True to run)\")\n",
    "    run_mc = False  # Set to True to run Monte Carlo\n",
    "    \n",
    "    if run_mc:\n",
    "        mc_results = monte_carlo_comparison(\n",
    "            n_simulations=20,\n",
    "            n_treated=50, \n",
    "            n_control=150, \n",
    "            p=5, \n",
    "            tau=2.0, \n",
    "            hetero=True\n",
    "        )\n",
    "        \n",
    "        # Save results\n",
    "        mc_results.to_csv('hungarian_comparison_results.csv', index=False)\n",
    "        print(\"Results saved to 'hungarian_comparison_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76cfed4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (Data Science)",
   "language": "python",
   "name": "py311ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
